{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Run in Colab development environment.\n",
        "\n"
      ],
      "metadata": {
        "id": "fIaAsPoIMJdd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jMqkTY4Ai8Q3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.io as io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlwrrsOKjCJA",
        "outputId": "7d2e2bee-3b90-4bb6-94ea-bbcec4efd241"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current working directory: /content\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#Use for Drive files\n",
        "\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1jDJhYvbNJi"
      },
      "source": [
        "https://pytorch.org/vision/main/models.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Z5u6-OihkeQ-"
      },
      "outputs": [],
      "source": [
        "from torchvision.io import decode_image\n",
        "\n",
        "from torchvision.models import swin_t, Swin_T_Weights\n",
        "from torchvision.models import swin_s, Swin_S_Weights\n",
        "from torchvision.models import swin_b, Swin_B_Weights\n",
        "from torchvision.models import swin_v2_t, Swin_V2_T_Weights\n",
        "from torchvision.models import swin_v2_s, Swin_V2_S_Weights\n",
        "from torchvision.models import swin_v2_b, Swin_V2_B_Weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1Tf5STcy-Nt"
      },
      "source": [
        "Images with Synthetic Object Added"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "hAHVCO2gzBNV",
        "outputId": "2fcafd3d-317b-41d0-80e2-4a9d82a7cdaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded images tensor shape: torch.Size([100, 3, 512, 1392])\n"
          ]
        }
      ],
      "source": [
        "def decode_multiple_images(image_paths): # Decodes multiple images from given paths using torchvision.\n",
        "    image_tensors = []\n",
        "    for path in image_paths:\n",
        "        try:\n",
        "            image_bytes = io.read_file(path)\n",
        "            image_tensor = io.decode_image(image_bytes)\n",
        "            if image_tensor.shape[0] == 4:\n",
        "              image_tensor = image_tensor[:3, :, :]\n",
        "            image_tensors.append(image_tensor)\n",
        "        except Exception as e:\n",
        "            print(f\"Error decoding image {path}: {e}\")\n",
        "    return torch.stack(image_tensors) if image_tensors else None\n",
        "\n",
        "image_folder = \"/content/drive/MyDrive/\" #image path\n",
        "\n",
        "image_files = [os.path.join(image_folder, f) for f in os.listdir(image_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "decoded_images = decode_multiple_images(image_files)\n",
        "\n",
        "if decoded_images is not None:\n",
        "    print(\"Decoded images tensor shape:\", decoded_images.shape) #Returns: torch.Tensor with the decoded images.\n",
        "else:\n",
        "    print(\"No images were successfully decoded.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "CYJlP8bPzPQB",
        "outputId": "f218ad92-a164-4481-c476-f2e4166e03be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/swin_v2_b-781e5279.pth\" to /root/.cache/torch/hub/checkpoints/swin_v2_b-781e5279.pth\n",
            "100%|██████████| 336M/336M [00:04<00:00, 82.8MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SwinTransformer(\n",
              "  (features): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))\n",
              "      (1): Permute()\n",
              "      (2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): SwinTransformerBlockV2(\n",
              "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): ShiftedWindowAttentionV2(\n",
              "          (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
              "          (proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "          (cpb_mlp): Sequential(\n",
              "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Linear(in_features=512, out_features=4, bias=False)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
              "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=512, out_features=128, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): SwinTransformerBlockV2(\n",
              "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): ShiftedWindowAttentionV2(\n",
              "          (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
              "          (proj): Linear(in_features=128, out_features=128, bias=True)\n",
              "          (cpb_mlp): Sequential(\n",
              "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Linear(in_features=512, out_features=4, bias=False)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.021739130434782608, mode=row)\n",
              "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (0): Linear(in_features=128, out_features=512, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=512, out_features=128, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (2): PatchMergingV2(\n",
              "      (reduction): Linear(in_features=512, out_features=256, bias=False)\n",
              "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (3): Sequential(\n",
              "      (0): SwinTransformerBlockV2(\n",
              "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): ShiftedWindowAttentionV2(\n",
              "          (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
              "          (proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (cpb_mlp): Sequential(\n",
              "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Linear(in_features=512, out_features=8, bias=False)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.043478260869565216, mode=row)\n",
              "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=1024, out_features=256, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): SwinTransformerBlockV2(\n",
              "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): ShiftedWindowAttentionV2(\n",
              "          (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
              "          (proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (cpb_mlp): Sequential(\n",
              "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Linear(in_features=512, out_features=8, bias=False)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.06521739130434782, mode=row)\n",
              "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=1024, out_features=256, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (4): PatchMergingV2(\n",
              "      (reduction): Linear(in_features=1024, out_features=512, bias=False)\n",
              "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (5): Sequential(\n",
              "      (0): SwinTransformerBlockV2(\n",
              "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): ShiftedWindowAttentionV2(\n",
              "          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (cpb_mlp): Sequential(\n",
              "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Linear(in_features=512, out_features=16, bias=False)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.08695652173913043, mode=row)\n",
              "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): SwinTransformerBlockV2(\n",
              "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): ShiftedWindowAttentionV2(\n",
              "          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (cpb_mlp): Sequential(\n",
              "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Linear(in_features=512, out_features=16, bias=False)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.10869565217391304, mode=row)\n",
              "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): SwinTransformerBlockV2(\n",
              "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): ShiftedWindowAttentionV2(\n",
              "          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (cpb_mlp): Sequential(\n",
              "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Linear(in_features=512, out_features=16, bias=False)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.13043478260869565, mode=row)\n",
              "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): SwinTransformerBlockV2(\n",
              "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): ShiftedWindowAttentionV2(\n",
              "          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (cpb_mlp): Sequential(\n",
              "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Linear(in_features=512, out_features=16, bias=False)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.15217391304347827, mode=row)\n",
              "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): SwinTransformerBlockV2(\n",
              "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): ShiftedWindowAttentionV2(\n",
              "          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (cpb_mlp): Sequential(\n",
              "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Linear(in_features=512, out_features=16, bias=False)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.17391304347826086, mode=row)\n",
              "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): SwinTransformerBlockV2(\n",
              "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): ShiftedWindowAttentionV2(\n",
              "          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (cpb_mlp): Sequential(\n",
              "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Linear(in_features=512, out_features=16, bias=False)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.1956521739130435, mode=row)\n",
              "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): SwinTransformerBlockV2(\n",
              "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): ShiftedWindowAttentionV2(\n",
              "          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (cpb_mlp): Sequential(\n",
              "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Linear(in_features=512, out_features=16, bias=False)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.21739130434782608, mode=row)\n",
              "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): SwinTransformerBlockV2(\n",
              "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): ShiftedWindowAttentionV2(\n",
              "          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (cpb_mlp): Sequential(\n",
              "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Linear(in_features=512, out_features=16, bias=False)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.2391304347826087, mode=row)\n",
              "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): SwinTransformerBlockV2(\n",
              "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): ShiftedWindowAttentionV2(\n",
              "          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (cpb_mlp): Sequential(\n",
              "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Linear(in_features=512, out_features=16, bias=False)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.2608695652173913, mode=row)\n",
              "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): SwinTransformerBlockV2(\n",
              "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): ShiftedWindowAttentionV2(\n",
              "          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (cpb_mlp): Sequential(\n",
              "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Linear(in_features=512, out_features=16, bias=False)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.2826086956521739, mode=row)\n",
              "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): SwinTransformerBlockV2(\n",
              "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): ShiftedWindowAttentionV2(\n",
              "          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (cpb_mlp): Sequential(\n",
              "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Linear(in_features=512, out_features=16, bias=False)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.30434782608695654, mode=row)\n",
              "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): SwinTransformerBlockV2(\n",
              "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): ShiftedWindowAttentionV2(\n",
              "          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (cpb_mlp): Sequential(\n",
              "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Linear(in_features=512, out_features=16, bias=False)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.32608695652173914, mode=row)\n",
              "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (12): SwinTransformerBlockV2(\n",
              "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): ShiftedWindowAttentionV2(\n",
              "          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (cpb_mlp): Sequential(\n",
              "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Linear(in_features=512, out_features=16, bias=False)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.34782608695652173, mode=row)\n",
              "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (13): SwinTransformerBlockV2(\n",
              "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): ShiftedWindowAttentionV2(\n",
              "          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (cpb_mlp): Sequential(\n",
              "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Linear(in_features=512, out_features=16, bias=False)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.3695652173913043, mode=row)\n",
              "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (14): SwinTransformerBlockV2(\n",
              "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): ShiftedWindowAttentionV2(\n",
              "          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (cpb_mlp): Sequential(\n",
              "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Linear(in_features=512, out_features=16, bias=False)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.391304347826087, mode=row)\n",
              "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (15): SwinTransformerBlockV2(\n",
              "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): ShiftedWindowAttentionV2(\n",
              "          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (cpb_mlp): Sequential(\n",
              "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Linear(in_features=512, out_features=16, bias=False)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.41304347826086957, mode=row)\n",
              "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (16): SwinTransformerBlockV2(\n",
              "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): ShiftedWindowAttentionV2(\n",
              "          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (cpb_mlp): Sequential(\n",
              "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Linear(in_features=512, out_features=16, bias=False)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.43478260869565216, mode=row)\n",
              "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (17): SwinTransformerBlockV2(\n",
              "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): ShiftedWindowAttentionV2(\n",
              "          (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
              "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (cpb_mlp): Sequential(\n",
              "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Linear(in_features=512, out_features=16, bias=False)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.45652173913043476, mode=row)\n",
              "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (6): PatchMergingV2(\n",
              "      (reduction): Linear(in_features=2048, out_features=1024, bias=False)\n",
              "      (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (7): Sequential(\n",
              "      (0): SwinTransformerBlockV2(\n",
              "        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): ShiftedWindowAttentionV2(\n",
              "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (cpb_mlp): Sequential(\n",
              "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Linear(in_features=512, out_features=32, bias=False)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.4782608695652174, mode=row)\n",
              "        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): SwinTransformerBlockV2(\n",
              "        (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): ShiftedWindowAttentionV2(\n",
              "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
              "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          (cpb_mlp): Sequential(\n",
              "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
              "            (1): ReLU(inplace=True)\n",
              "            (2): Linear(in_features=512, out_features=32, bias=False)\n",
              "          )\n",
              "        )\n",
              "        (stochastic_depth): StochasticDepth(p=0.5, mode=row)\n",
              "        (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): MLP(\n",
              "          (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (1): GELU(approximate='none')\n",
              "          (2): Dropout(p=0.0, inplace=False)\n",
              "          (3): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (4): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "  (permute): Permute()\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (head): Linear(in_features=1024, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Swin Model series\n",
        "\n",
        "#weights = Swin_T_Weights.DEFAULT\n",
        "#model = swin_t(weights=weights)\n",
        "#weights = Swin_S_Weights.DEFAULT\n",
        "#model = swin_s(weights=weights)\n",
        "#weights = Swin_B_Weights.DEFAULT\n",
        "#model = swin_b(weights=weights)\n",
        "#weights = Swin_V2_T_Weights.DEFAULT\n",
        "#model = swin_v2_t(weights=weights)\n",
        "#weights = Swin_V2_S_Weights.DEFAULT\n",
        "#model = swin_v2_s(weights=weights)#\n",
        "weights = Swin_V2_B_Weights.DEFAULT\n",
        "model = swin_v2_b(weights=weights)\n",
        "\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vDdwriJI2vE"
      },
      "source": [
        "https://pytorch.org/vision/main/models.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "pOOLydOZzTyr",
        "outputId": "e146609a-85da-4dd1-c383-c863a03a5e81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bicycle-built-for-two: 32.4%\n",
            "bicycle-built-for-two: 38.6%\n",
            "bicycle-built-for-two: 52.5%\n",
            "bicycle-built-for-two: 75.8%\n",
            "bicycle-built-for-two: 69.5%\n",
            "bicycle-built-for-two: 41.0%\n",
            "bicycle-built-for-two: 50.8%\n",
            "bicycle-built-for-two: 39.2%\n",
            "bicycle-built-for-two: 45.7%\n",
            "bicycle-built-for-two: 48.4%\n",
            "bicycle-built-for-two: 33.4%\n",
            "bicycle-built-for-two: 80.5%\n",
            "bicycle-built-for-two: 53.8%\n",
            "bicycle-built-for-two: 31.8%\n",
            "bicycle-built-for-two: 71.6%\n",
            "bicycle-built-for-two: 58.7%\n",
            "bicycle-built-for-two: 20.0%\n",
            "tricycle: 43.0%\n",
            "bicycle-built-for-two: 47.9%\n",
            "tricycle: 49.2%\n",
            "bicycle-built-for-two: 82.7%\n",
            "bicycle-built-for-two: 39.7%\n",
            "bicycle-built-for-two: 47.8%\n",
            "bicycle-built-for-two: 56.3%\n",
            "bicycle-built-for-two: 73.4%\n",
            "bicycle-built-for-two: 24.5%\n",
            "bicycle-built-for-two: 57.6%\n",
            "tricycle: 74.9%\n",
            "tricycle: 28.3%\n",
            "bicycle-built-for-two: 38.7%\n",
            "bicycle-built-for-two: 45.9%\n",
            "bicycle-built-for-two: 31.2%\n",
            "bicycle-built-for-two: 54.4%\n",
            "bicycle-built-for-two: 64.4%\n",
            "bicycle-built-for-two: 58.8%\n",
            "tricycle: 46.4%\n",
            "bicycle-built-for-two: 53.9%\n",
            "bicycle-built-for-two: 59.2%\n",
            "bicycle-built-for-two: 60.9%\n",
            "bicycle-built-for-two: 75.4%\n",
            "bicycle-built-for-two: 60.8%\n",
            "bicycle-built-for-two: 74.2%\n",
            "bicycle-built-for-two: 61.9%\n",
            "bicycle-built-for-two: 77.9%\n",
            "bicycle-built-for-two: 69.9%\n",
            "bicycle-built-for-two: 45.1%\n",
            "bicycle-built-for-two: 55.6%\n",
            "bicycle-built-for-two: 39.7%\n",
            "bicycle-built-for-two: 77.8%\n",
            "bicycle-built-for-two: 62.9%\n",
            "bicycle-built-for-two: 53.3%\n",
            "bicycle-built-for-two: 65.5%\n",
            "tricycle: 30.0%\n",
            "bicycle-built-for-two: 72.1%\n",
            "bicycle-built-for-two: 45.9%\n",
            "bicycle-built-for-two: 66.6%\n",
            "bicycle-built-for-two: 35.7%\n",
            "bicycle-built-for-two: 81.8%\n",
            "bicycle-built-for-two: 51.2%\n",
            "bicycle-built-for-two: 40.0%\n",
            "bicycle-built-for-two: 49.1%\n",
            "bicycle-built-for-two: 65.2%\n",
            "bicycle-built-for-two: 54.5%\n",
            "bicycle-built-for-two: 42.5%\n",
            "bicycle-built-for-two: 65.9%\n",
            "bicycle-built-for-two: 70.7%\n",
            "bicycle-built-for-two: 54.2%\n",
            "bicycle-built-for-two: 61.4%\n",
            "bicycle-built-for-two: 69.8%\n",
            "bicycle-built-for-two: 53.4%\n",
            "bicycle-built-for-two: 58.7%\n",
            "bicycle-built-for-two: 59.6%\n",
            "bicycle-built-for-two: 54.1%\n",
            "bicycle-built-for-two: 71.8%\n",
            "bicycle-built-for-two: 71.4%\n",
            "bicycle-built-for-two: 43.2%\n",
            "bicycle-built-for-two: 21.6%\n",
            "bicycle-built-for-two: 79.0%\n",
            "bicycle-built-for-two: 42.8%\n",
            "tricycle: 30.8%\n",
            "bicycle-built-for-two: 36.3%\n",
            "bicycle-built-for-two: 50.5%\n",
            "bicycle-built-for-two: 29.0%\n",
            "bicycle-built-for-two: 29.8%\n",
            "bicycle-built-for-two: 52.8%\n",
            "bicycle-built-for-two: 72.0%\n",
            "bicycle-built-for-two: 81.2%\n",
            "bicycle-built-for-two: 27.7%\n",
            "bicycle-built-for-two: 51.0%\n",
            "bicycle-built-for-two: 52.5%\n",
            "bicycle-built-for-two: 62.7%\n",
            "bicycle-built-for-two: 54.5%\n",
            "bicycle-built-for-two: 54.6%\n",
            "bicycle-built-for-two: 49.5%\n",
            "bicycle-built-for-two: 34.7%\n",
            "bicycle-built-for-two: 51.8%\n",
            "bicycle-built-for-two: 39.4%\n",
            "bicycle-built-for-two: 39.1%\n",
            "bicycle-built-for-two: 46.6%\n",
            "bicycle-built-for-two: 74.7%\n"
          ]
        }
      ],
      "source": [
        "img = decoded_images\n",
        "\n",
        "# Initialize\n",
        "preprocess = weights.transforms()\n",
        "\n",
        "# Apply inference preprocessing transforms **and prediction for each image\n",
        "for i in range(img.shape[0]):  # Iterate through each image in decoded_images\n",
        "    single_img = img[i]  # Get a single image from the tensor\n",
        "\n",
        "    # Convert the image to RGB if it has 4 channels (RGBA)\n",
        "    if single_img.shape[0] == 4:\n",
        "        single_img = single_img[:3, :, :]  # Select only the first 3 channels (RGB)\n",
        "\n",
        "    batch = preprocess(single_img).unsqueeze(0)\n",
        "\n",
        "    # Use the model to predict category\n",
        "    prediction = model(batch).squeeze(0).softmax(0)\n",
        "    class_id = prediction.argmax().item()\n",
        "    score = prediction[class_id].item() #score/confidence of prediction\n",
        "\n",
        "    category_name = weights.meta[\"categories\"][class_id]\n",
        "    print(f\"{category_name}: {100 * score:.1f}%\")\n",
        "\n",
        "    with open(os.path.join(image_folder, 'testrun.csv'), 'a') as file:\n",
        "      file.write(category_name + ',' + str(100*score) + '\\n') # Concatenate the strings into a single string before writing"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}